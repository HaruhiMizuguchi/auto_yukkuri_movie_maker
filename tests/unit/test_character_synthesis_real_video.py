"""
ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - å®Ÿå‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆ

å®Ÿéš›ã®OpenCVã¨ffmpegã‚’ä½¿ç”¨ã—ã¦å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã€
ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã€ã‚µã‚¤ã‚ºã€ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import unittest
import os
import tempfile
import shutil
import asyncio
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.modules.character_synthesizer import (
    CharacterSynthesizer, 
    CharacterFrame,
    LipSyncFrame,
    EmotionFrame,
    CharacterSynthesizerError
)
from src.dao.character_synthesis_dao import CharacterSynthesisDAO
from src.core.file_system_manager import FileSystemManager
from src.core.config_manager import ConfigManager
from src.core.database_manager import DatabaseManager

# å‹•ç”»å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import cv2
    import numpy as np
    import ffmpeg
    REAL_VIDEO_PROCESSING_AVAILABLE = True
except ImportError:
    REAL_VIDEO_PROCESSING_AVAILABLE = False
    cv2 = None
    np = None
    ffmpeg = None


class TestCharacterSynthesisRealVideo(unittest.TestCase):
    """å®Ÿå‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""

    @classmethod
    def setUpClass(cls):
        """ã‚¯ãƒ©ã‚¹åˆæœŸåŒ–"""
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(level=logging.INFO)
        cls.logger = logging.getLogger(__name__)
        
        # ãƒ†ã‚¹ãƒˆç’°å¢ƒãƒã‚§ãƒƒã‚¯
        if not REAL_VIDEO_PROCESSING_AVAILABLE:
            cls.logger.warning("Real video processing libraries not available. Tests will be skipped.")

    def setUp(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨ï¼ˆä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä»£ã‚ã‚Šã«ï¼‰
        self.test_dir = os.path.join(os.getcwd(), "outputs")
        os.makedirs(self.test_dir, exist_ok=True)
        
        self.project_id = f"test-real-video-{datetime.now().strftime('%Y%m%d-%H%M%S')}"

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šï¼ˆä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ï¼‰
        temp_dir = tempfile.mkdtemp(prefix="test_db_")
        self.db_path = os.path.join(temp_dir, "test_database.db")
        self.db_manager = DatabaseManager(self.db_path)

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.db_manager.initialize()

        # DAOä½œæˆ
        self.dao = CharacterSynthesisDAO(self.db_manager)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½œæˆï¼ˆä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç”¨ï¼‰
        self.file_manager = FileSystemManager(temp_dir)

        # è¨­å®šãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½œæˆ
        self.config_manager = ConfigManager()

        # CharacterSynthesizerä½œæˆ
        self.synthesizer = CharacterSynthesizer(
            dao=self.dao,
            file_manager=self.file_manager,
            config_manager=self.config_manager,
            logger=self.logger
        )

        # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
        self._setup_test_project()

    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆå¾Œã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        # æ³¨æ„: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¯ outputs ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã‚‹ãŸã‚å‰Šé™¤ã—ãªã„
        print(f"ğŸ“ ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¯ outputs ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™: {self.test_dir}")
        
        try:
            if hasattr(self, 'db_manager'):
                self.db_manager.close()
        except Exception as e:
            self.logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ­ãƒ¼ã‚ºã‚¨ãƒ©ãƒ¼: {e}")

    def _setup_test_project(self):
        """ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š"""
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        project_dir = self.file_manager.create_project_directory(self.project_id)
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä½œæˆï¼ˆå¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚’æº€ãŸã™ãŸã‚ï¼‰
        from src.core.project_repository import ProjectRepository
        project_repo = ProjectRepository(self.db_manager)
        project_repo.create_project(
            project_id=self.project_id,
            theme="ãƒ†ã‚¹ãƒˆç”¨ãƒ†ãƒ¼ãƒ - å®Ÿå‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆ",
            target_length_minutes=5.0,
            config={
                "target_duration": 300,
                "style": "casual",
                "description": "Test project for real video generation"
            }
        )
        
        # ãƒ†ã‚¹ãƒˆç”¨éŸ³å£°ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        audio_metadata = {
            "total_duration": 5.0,
            "segments": [
                {
                    "start_time": 0.0,
                    "end_time": 2.5,
                    "speaker": "reimu",
                    "text": "ã“ã‚“ã«ã¡ã¯ã€éœŠå¤¢ã§ã™ã€‚",
                    "timestamps": [
                        {"start": 0.0, "end": 0.5, "phoneme": "k"},
                        {"start": 0.5, "end": 1.0, "phoneme": "o"},
                        {"start": 1.0, "end": 1.5, "phoneme": "n"},
                        {"start": 1.5, "end": 2.0, "phoneme": "n"},
                        {"start": 2.0, "end": 2.5, "phoneme": "i"}
                    ]
                },
                {
                    "start_time": 2.5,
                    "end_time": 5.0,
                    "speaker": "marisa",
                    "text": "é­”ç†æ²™ã ãœï¼",
                    "timestamps": [
                        {"start": 2.5, "end": 3.0, "phoneme": "m"},
                        {"start": 3.0, "end": 3.5, "phoneme": "a"},
                        {"start": 3.5, "end": 4.0, "phoneme": "r"},
                        {"start": 4.0, "end": 4.5, "phoneme": "i"},
                        {"start": 4.5, "end": 5.0, "phoneme": "s"}
                    ]
                }
            ]
        }
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š
        character_config = {
            "characters": {
                "reimu": {"position": [400, 300], "scale": 1.0},
                "marisa": {"position": [600, 300], "scale": 1.0}
            },
            "animation": {
                "frame_rate": 30,
                "width": 1920,
                "height": 1080
            }
        }
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        self.dao.save_audio_metadata(self.project_id, audio_metadata)
        self.dao.save_character_config(self.project_id, character_config)

    @unittest.skipIf(not REAL_VIDEO_PROCESSING_AVAILABLE, "Real video processing libraries not available")
    def test_01_real_standard_video_generation(self):
        """ãƒ†ã‚¹ãƒˆ1: å®Ÿéš›ã®æ¨™æº–å‹•ç”»ç”Ÿæˆ"""
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        character_frames = self._create_test_character_frames()
        
        # å‹•ç”»è¨­å®š
        video_config = {
            "transparency": False,
            "width": 1920,
            "height": 1080,
            "frame_rate": 30,
            "background_color": [240, 248, 255, 255],
            "emotion_effects": True,
            "color_correction": True,
            "sharpening": False
        }
        
        # å‡ºåŠ›ãƒ‘ã‚¹
        output_path = os.path.join(self.test_dir, f"{self.project_id}_standard.mp4")
        
        # å‹•ç”»ç”Ÿæˆå®Ÿè¡Œ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(
                self.synthesizer._generate_video_with_opencv_enhanced(
                    character_frames, output_path, video_config
                )
            )
        finally:
            loop.close()
        
        # æ¤œè¨¼
        self.assertTrue(os.path.exists(output_path), "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        file_size = os.path.getsize(output_path)
        self.assertGreater(file_size, 0, "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºãŒ0ã§ã™")
        
        # OpenCVã§å‹•ç”»ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’ç¢ºèª
        cap = cv2.VideoCapture(output_path)
        self.assertTrue(cap.isOpened(), "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒé–‹ã‘ã¾ã›ã‚“")
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ç¢ºèª
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        cap.release()
        
        # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£æ¤œè¨¼
        self.assertEqual(width, 1920, f"å‹•ç”»å¹…ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™: {width}")
        self.assertEqual(height, 1080, f"å‹•ç”»é«˜ã•ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™: {height}")
        self.assertAlmostEqual(fps, 30, delta=1, msg=f"ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™: {fps}")
        self.assertGreater(frame_count, 0, "ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ0ã§ã™")
        
        print(f"âœ… æ¨™æº–å‹•ç”»ç”ŸæˆæˆåŠŸ: {output_path}")
        print(f"   ã‚µã‚¤ã‚º: {width}x{height}, FPS: {fps}, ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
        print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size / 1024 / 1024:.2f}MB")

    @unittest.skipIf(not REAL_VIDEO_PROCESSING_AVAILABLE, "Real video processing libraries not available")
    def test_02_real_transparent_video_generation(self):
        """ãƒ†ã‚¹ãƒˆ2: å®Ÿéš›ã®é€æ˜èƒŒæ™¯å‹•ç”»ç”Ÿæˆ"""
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        character_frames = self._create_test_character_frames()
        
        # é€æ˜èƒŒæ™¯å‹•ç”»è¨­å®š
        video_config = {
            "transparency": True,
            "width": 1920,
            "height": 1080,
            "frame_rate": 30,
            "codec": "libx264",
            "crf": 23,
            "preset": "medium",
            "emotion_effects": True,
            "quiet": True
        }
        
        # å‡ºåŠ›ãƒ‘ã‚¹
        output_path = os.path.join(self.test_dir, f"{self.project_id}_transparent.mp4")
        
        # å‹•ç”»ç”Ÿæˆå®Ÿè¡Œ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(
                self.synthesizer._generate_video_with_opencv_enhanced(
                    character_frames, output_path, video_config
                )
            )
        finally:
            loop.close()
        
        # æ¤œè¨¼
        self.assertTrue(os.path.exists(output_path), "é€æ˜èƒŒæ™¯å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        file_size = os.path.getsize(output_path)
        self.assertGreater(file_size, 0, "é€æ˜èƒŒæ™¯å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºãŒ0ã§ã™")
        
        # ffprobeã§å‹•ç”»æƒ…å ±ã‚’å–å¾—
        try:
            probe = ffmpeg.probe(output_path)
            video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)
            
            if video_stream:
                width = int(video_stream['width'])
                height = int(video_stream['height'])
                pix_fmt = video_stream.get('pix_fmt', '')
                
                # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£æ¤œè¨¼
                self.assertEqual(width, 1920, f"é€æ˜å‹•ç”»å¹…ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™: {width}")
                self.assertEqual(height, 1080, f"é€æ˜å‹•ç”»é«˜ã•ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™: {height}")
                
                print(f"âœ… é€æ˜èƒŒæ™¯å‹•ç”»ç”ŸæˆæˆåŠŸ: {output_path}")
                print(f"   ã‚µã‚¤ã‚º: {width}x{height}, ãƒ”ã‚¯ã‚»ãƒ«å½¢å¼: {pix_fmt}")
                print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size / 1024 / 1024:.2f}MB")
            else:
                self.fail("å‹•ç”»ã‚¹ãƒˆãƒªãƒ¼ãƒ æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                
        except Exception as e:
            self.logger.warning(f"ffprobeå®Ÿè¡Œã‚¨ãƒ©ãƒ¼ï¼ˆå‹•ç”»ã¯ç”Ÿæˆæ¸ˆã¿ï¼‰: {e}")
            print(f"âœ… é€æ˜èƒŒæ™¯å‹•ç”»ç”ŸæˆæˆåŠŸ: {output_path}")
            print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size / 1024 / 1024:.2f}MB")

    @unittest.skipIf(not REAL_VIDEO_PROCESSING_AVAILABLE, "Real video processing libraries not available")
    def test_03_real_frame_image_creation(self):
        """ãƒ†ã‚¹ãƒˆ3: å®Ÿéš›ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒä½œæˆ"""
        # ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ 
        test_frame = CharacterFrame(
            timestamp=1.0,
            speaker="reimu",
            mouth_shape="a",
            emotion="happy",
            position=(960, 540),
            scale=1.0
        )
        
        # ç”»åƒè¨­å®š
        width, height = 1920, 1080
        video_config = {
            "emotion_effects": True,
            "background_color": [240, 248, 255, 255]
        }
        
        # é€æ˜èƒŒæ™¯ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒä½œæˆ
        transparent_img = self.synthesizer._create_transparent_frame_image(
            test_frame, width, height, video_config
        )
        
        # æ¨™æº–ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒä½œæˆ
        standard_img = self.synthesizer._create_optimized_frame_image(
            test_frame, width, height, video_config
        )
        
        # æ¤œè¨¼
        self.assertIsNotNone(transparent_img, "é€æ˜èƒŒæ™¯ç”»åƒãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        self.assertIsNotNone(standard_img, "æ¨™æº–ç”»åƒãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ç”»åƒã‚µã‚¤ã‚ºç¢ºèª
        self.assertEqual(transparent_img.shape, (height, width, 4), "é€æ˜èƒŒæ™¯ç”»åƒã®ã‚µã‚¤ã‚ºãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
        self.assertEqual(standard_img.shape, (height, width, 4), "æ¨™æº–ç”»åƒã®ã‚µã‚¤ã‚ºãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
        
        # ç”»åƒä¿å­˜ï¼ˆç¢ºèªç”¨ï¼‰
        transparent_path = os.path.join(self.test_dir, "test_transparent_frame.png")
        standard_path = os.path.join(self.test_dir, "test_standard_frame.png")
        
        cv2.imwrite(transparent_path, transparent_img)
        cv2.imwrite(standard_path, standard_img)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        self.assertTrue(os.path.exists(transparent_path), "é€æ˜èƒŒæ™¯ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        self.assertTrue(os.path.exists(standard_path), "æ¨™æº–ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        print(f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒä½œæˆæˆåŠŸ:")
        print(f"   é€æ˜èƒŒæ™¯: {transparent_path}")
        print(f"   æ¨™æº–èƒŒæ™¯: {standard_path}")

    @unittest.skipIf(not REAL_VIDEO_PROCESSING_AVAILABLE, "Real video processing libraries not available")
    def test_04_real_multiple_frame_rates(self):
        """ãƒ†ã‚¹ãƒˆ4: è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã§ã®å‹•ç”»ç”Ÿæˆ"""
        frame_rates = [24, 30, 60]
        character_frames = self._create_test_character_frames()
        
        for fps in frame_rates:
            with self.subTest(fps=fps):
                # å‹•ç”»è¨­å®š
                video_config = {
                    "transparency": False,
                    "width": 1280,
                    "height": 720,
                    "frame_rate": fps,
                    "background_color": [200, 220, 240, 255]
                }
                
                # å‡ºåŠ›ãƒ‘ã‚¹
                output_path = os.path.join(self.test_dir, f"{self.project_id}_{fps}fps.mp4")
                
                # å‹•ç”»ç”Ÿæˆå®Ÿè¡Œ
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    loop.run_until_complete(
                        self.synthesizer._generate_video_with_opencv_enhanced(
                            character_frames, output_path, video_config
                        )
                    )
                finally:
                    loop.close()
                
                # æ¤œè¨¼
                self.assertTrue(os.path.exists(output_path), f"{fps}fpså‹•ç”»ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
                # OpenCVã§ç¢ºèª
                cap = cv2.VideoCapture(output_path)
                self.assertTrue(cap.isOpened(), f"{fps}fpså‹•ç”»ãŒé–‹ã‘ã¾ã›ã‚“")
                
                actual_fps = cap.get(cv2.CAP_PROP_FPS)
                cap.release()
                
                self.assertAlmostEqual(actual_fps, fps, delta=1, 
                                     msg=f"ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™: {actual_fps} != {fps}")
                
                print(f"âœ… {fps}fpså‹•ç”»ç”ŸæˆæˆåŠŸ: {output_path}")

    def _create_test_character_frames(self) -> List[CharacterFrame]:
        """ãƒ†ã‚¹ãƒˆç”¨ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ"""
        frames = []
        duration = 5.0  # 5ç§’
        fps = 30
        total_frames = int(duration * fps)
        
        for i in range(total_frames):
            timestamp = i / fps
            
            # è©±è€…åˆ‡ã‚Šæ›¿ãˆï¼ˆ2.5ç§’ã§åˆ‡ã‚Šæ›¿ãˆï¼‰
            speaker = "reimu" if timestamp < 2.5 else "marisa"
            
            # å£å½¢çŠ¶ï¼ˆç°¡å˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
            mouth_shapes = ["a", "i", "u", "e", "o", "silence"]
            mouth_shape = mouth_shapes[i % len(mouth_shapes)]
            
            # æ„Ÿæƒ…ï¼ˆæ™‚é–“ã«å¿œã˜ã¦å¤‰åŒ–ï¼‰
            if timestamp < 1.5:
                emotion = "neutral"
            elif timestamp < 3.0:
                emotion = "happy"
            elif timestamp < 4.0:
                emotion = "surprised"
            else:
                emotion = "happy"
            
            # ä½ç½®ï¼ˆè©±è€…ã«ã‚ˆã£ã¦å¤‰æ›´ï¼‰
            position = (400, 540) if speaker == "reimu" else (1520, 540)
            
            frame = CharacterFrame(
                timestamp=timestamp,
                speaker=speaker,
                mouth_shape=mouth_shape,
                emotion=emotion,
                position=position,
                scale=1.0
            )
            frames.append(frame)
        
        return frames


def run_real_video_tests():
    """å®Ÿå‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    if not REAL_VIDEO_PROCESSING_AVAILABLE:
        print("âš ï¸ å®Ÿå‹•ç”»ç”Ÿæˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        print("å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª: opencv-python, ffmpeg-python")
        return
    
    unittest.main(verbosity=2)


if __name__ == "__main__":
    run_real_video_tests() 